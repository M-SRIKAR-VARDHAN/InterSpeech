{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š Stage 1.5: Dataset Analysis\n",
    "\n",
    "**Purpose:** Analyze the unified dataset before feature extraction\n",
    "\n",
    "**Runs on:** CPU (no GPU needed)\n",
    "\n",
    "**Output:** `unified/stats/` folder with all analysis results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Mount Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (most are pre-installed in Colab)\n",
    "!pip install -q librosa soundfile matplotlib seaborn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"âœ… Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION - Update this path if needed\n",
    "# ============================================================\n",
    "\n",
    "BASE_DIR = Path(\"/content/drive/MyDrive/Liquidity_Research/unified\")\n",
    "AUDIO_DIR = BASE_DIR / \"audio_16k\"\n",
    "METADATA_PATH = BASE_DIR / \"metadata.csv\"\n",
    "SPLITS_PATH = BASE_DIR / \"splits.json\"\n",
    "STATS_DIR = BASE_DIR / \"stats\"\n",
    "\n",
    "# Create stats directory\n",
    "STATS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Stats output:   {STATS_DIR}\")\n",
    "print(f\"\\nDirectory exists: {BASE_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "df = pd.read_csv(METADATA_PATH)\n",
    "print(f\"Loaded {len(df):,} utterances\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load splits\n",
    "with open(SPLITS_PATH, 'r') as f:\n",
    "    splits = json.load(f)\n",
    "\n",
    "print(\"Splits configuration:\")\n",
    "print(json.dumps(splits['config'], indent=2))\n",
    "print(f\"\\nTrain: {splits['train']['num_speakers']} speakers, {splits['train']['num_utterances']} utterances\")\n",
    "print(f\"Val:   {splits['val']['num_speakers']} speakers, {splits['val']['num_utterances']} utterances\")\n",
    "print(f\"Test:  {splits['test']['num_speakers']} speakers, {splits['test']['num_utterances']} utterances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# OVERALL STATISTICS\n",
    "# ============================================================\n",
    "\n",
    "stats = {\n",
    "    'total_utterances': len(df),\n",
    "    'total_speakers': df['speaker_id'].nunique(),\n",
    "    'total_duration_hours': df['duration'].sum() / 3600,\n",
    "    'total_duration_seconds': df['duration'].sum(),\n",
    "    'avg_duration': df['duration'].mean(),\n",
    "    'min_duration': df['duration'].min(),\n",
    "    'max_duration': df['duration'].max(),\n",
    "    'median_duration': df['duration'].median(),\n",
    "    'std_duration': df['duration'].std(),\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"OVERALL DATASET STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total utterances:     {stats['total_utterances']:,}\")\n",
    "print(f\"Total speakers:       {stats['total_speakers']}\")\n",
    "print(f\"Total duration:       {stats['total_duration_hours']:.2f} hours\")\n",
    "print(f\"\")\n",
    "print(f\"Duration statistics:\")\n",
    "print(f\"  Min:    {stats['min_duration']:.2f}s\")\n",
    "print(f\"  Max:    {stats['max_duration']:.2f}s\")\n",
    "print(f\"  Mean:   {stats['avg_duration']:.2f}s\")\n",
    "print(f\"  Median: {stats['median_duration']:.2f}s\")\n",
    "print(f\"  Std:    {stats['std_duration']:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BY DATASET (VCTK vs ESD)\n",
    "# ============================================================\n",
    "\n",
    "dataset_stats = df.groupby('dataset').agg({\n",
    "    'utt_id': 'count',\n",
    "    'speaker_id': 'nunique',\n",
    "    'duration': ['sum', 'mean', 'min', 'max', 'std']\n",
    "}).round(3)\n",
    "\n",
    "dataset_stats.columns = ['utterances', 'speakers', 'total_sec', 'avg_sec', 'min_sec', 'max_sec', 'std_sec']\n",
    "dataset_stats['hours'] = dataset_stats['total_sec'] / 3600\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BY DATASET\")\n",
    "print(\"=\"*60)\n",
    "print(dataset_stats.to_string())\n",
    "\n",
    "stats['by_dataset'] = dataset_stats.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BY GENDER\n",
    "# ============================================================\n",
    "\n",
    "gender_stats = df.groupby('gender').agg({\n",
    "    'utt_id': 'count',\n",
    "    'speaker_id': 'nunique',\n",
    "    'duration': 'sum'\n",
    "}).round(3)\n",
    "gender_stats.columns = ['utterances', 'speakers', 'total_sec']\n",
    "gender_stats['hours'] = gender_stats['total_sec'] / 3600\n",
    "gender_stats['pct'] = (gender_stats['utterances'] / len(df) * 100).round(1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BY GENDER\")\n",
    "print(\"=\"*60)\n",
    "print(gender_stats.to_string())\n",
    "\n",
    "stats['by_gender'] = gender_stats.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BY EMOTION (Important for ESD)\n",
    "# ============================================================\n",
    "\n",
    "emotion_stats = df.groupby('emotion').agg({\n",
    "    'utt_id': 'count',\n",
    "    'speaker_id': 'nunique',\n",
    "    'duration': 'sum'\n",
    "}).round(3)\n",
    "emotion_stats.columns = ['utterances', 'speakers', 'total_sec']\n",
    "emotion_stats['hours'] = emotion_stats['total_sec'] / 3600\n",
    "emotion_stats['pct'] = (emotion_stats['utterances'] / len(df) * 100).round(1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BY EMOTION\")\n",
    "print(\"=\"*60)\n",
    "print(emotion_stats.sort_values('utterances', ascending=False).to_string())\n",
    "\n",
    "stats['by_emotion'] = emotion_stats.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BY ACCENT (VCTK has various accents)\n",
    "# ============================================================\n",
    "\n",
    "accent_stats = df.groupby('accent').agg({\n",
    "    'utt_id': 'count',\n",
    "    'speaker_id': 'nunique',\n",
    "    'duration': 'sum'\n",
    "}).round(3)\n",
    "accent_stats.columns = ['utterances', 'speakers', 'total_sec']\n",
    "accent_stats['hours'] = accent_stats['total_sec'] / 3600\n",
    "accent_stats['pct'] = (accent_stats['utterances'] / len(df) * 100).round(1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BY ACCENT\")\n",
    "print(\"=\"*60)\n",
    "print(accent_stats.sort_values('utterances', ascending=False).to_string())\n",
    "\n",
    "stats['by_accent'] = accent_stats.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PER-SPEAKER STATISTICS\n",
    "# ============================================================\n",
    "\n",
    "speaker_stats = df.groupby('speaker_id').agg({\n",
    "    'utt_id': 'count',\n",
    "    'duration': ['sum', 'mean'],\n",
    "    'dataset': 'first',\n",
    "    'gender': 'first',\n",
    "    'accent': 'first'\n",
    "}).round(3)\n",
    "speaker_stats.columns = ['utterances', 'total_sec', 'avg_sec', 'dataset', 'gender', 'accent']\n",
    "speaker_stats['minutes'] = speaker_stats['total_sec'] / 60\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PER-SPEAKER STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Utterances per speaker:\")\n",
    "print(f\"  Min:    {speaker_stats['utterances'].min()}\")\n",
    "print(f\"  Max:    {speaker_stats['utterances'].max()}\")\n",
    "print(f\"  Mean:   {speaker_stats['utterances'].mean():.1f}\")\n",
    "print(f\"  Median: {speaker_stats['utterances'].median():.1f}\")\n",
    "print(f\"\")\n",
    "print(f\"Duration per speaker:\")\n",
    "print(f\"  Min:    {speaker_stats['minutes'].min():.1f} minutes\")\n",
    "print(f\"  Max:    {speaker_stats['minutes'].max():.1f} minutes\")\n",
    "print(f\"  Mean:   {speaker_stats['minutes'].mean():.1f} minutes\")\n",
    "print(f\"  Median: {speaker_stats['minutes'].median():.1f} minutes\")\n",
    "\n",
    "# Top 10 speakers by utterances\n",
    "print(\"\\nTop 10 speakers by utterances:\")\n",
    "print(speaker_stats.nlargest(10, 'utterances')[['utterances', 'minutes', 'dataset', 'gender']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Split Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAIN/VAL/TEST SPLIT ANALYSIS\n",
    "# ============================================================\n",
    "\n",
    "# Add split column to dataframe\n",
    "df['split'] = 'unknown'\n",
    "df.loc[df['speaker_id'].isin(splits['train']['speakers']), 'split'] = 'train'\n",
    "df.loc[df['speaker_id'].isin(splits['val']['speakers']), 'split'] = 'val'\n",
    "df.loc[df['speaker_id'].isin(splits['test']['speakers']), 'split'] = 'test'\n",
    "\n",
    "split_stats = df.groupby('split').agg({\n",
    "    'utt_id': 'count',\n",
    "    'speaker_id': 'nunique',\n",
    "    'duration': 'sum'\n",
    "}).round(3)\n",
    "split_stats.columns = ['utterances', 'speakers', 'total_sec']\n",
    "split_stats['hours'] = split_stats['total_sec'] / 3600\n",
    "split_stats['pct_utts'] = (split_stats['utterances'] / len(df) * 100).round(1)\n",
    "split_stats['pct_spks'] = (split_stats['speakers'] / df['speaker_id'].nunique() * 100).round(1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAIN/VAL/TEST SPLIT ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(split_stats.to_string())\n",
    "\n",
    "stats['by_split'] = split_stats.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CHECK SPLIT BALANCE BY GENDER, EMOTION, DATASET\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SPLIT BALANCE CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Gender balance per split\n",
    "print(\"\\nGender distribution per split:\")\n",
    "gender_split = pd.crosstab(df['split'], df['gender'], normalize='index') * 100\n",
    "print(gender_split.round(1).to_string())\n",
    "\n",
    "# Dataset balance per split\n",
    "print(\"\\nDataset distribution per split:\")\n",
    "dataset_split = pd.crosstab(df['split'], df['dataset'], normalize='index') * 100\n",
    "print(dataset_split.round(1).to_string())\n",
    "\n",
    "# Emotion distribution per split (mainly for ESD)\n",
    "print(\"\\nEmotion distribution per split:\")\n",
    "emotion_split = pd.crosstab(df['split'], df['emotion'], normalize='index') * 100\n",
    "print(emotion_split.round(1).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VERIFY AUDIO FILES EXIST\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VERIFYING AUDIO FILES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "missing_files = []\n",
    "existing_files = 0\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Checking files\"):\n",
    "    audio_path = BASE_DIR / row['audio_path']\n",
    "    if audio_path.exists():\n",
    "        existing_files += 1\n",
    "    else:\n",
    "        missing_files.append({\n",
    "            'utt_id': row['utt_id'],\n",
    "            'expected_path': str(audio_path)\n",
    "        })\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Existing:  {existing_files:,} ({existing_files/len(df)*100:.1f}%)\")\n",
    "print(f\"  Missing:   {len(missing_files):,} ({len(missing_files)/len(df)*100:.1f}%)\")\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"\\nFirst 10 missing files:\")\n",
    "    for mf in missing_files[:10]:\n",
    "        print(f\"  {mf['utt_id']}\")\n",
    "\n",
    "stats['file_verification'] = {\n",
    "    'existing': existing_files,\n",
    "    'missing': len(missing_files),\n",
    "    'missing_files': missing_files[:100]  # Save first 100 for debugging\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# COUNT ACTUAL FILES ON DISK\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COUNTING FILES ON DISK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "speaker_dirs = list(AUDIO_DIR.iterdir())\n",
    "print(f\"Speaker directories: {len(speaker_dirs)}\")\n",
    "\n",
    "file_counts = {}\n",
    "total_files = 0\n",
    "\n",
    "for spk_dir in tqdm(speaker_dirs, desc=\"Counting files\"):\n",
    "    if spk_dir.is_dir():\n",
    "        wav_files = list(spk_dir.glob(\"*.wav\"))\n",
    "        file_counts[spk_dir.name] = len(wav_files)\n",
    "        total_files += len(wav_files)\n",
    "\n",
    "print(f\"\\nTotal .wav files on disk: {total_files:,}\")\n",
    "print(f\"Total in metadata.csv:    {len(df):,}\")\n",
    "print(f\"Difference:               {total_files - len(df):,}\")\n",
    "\n",
    "stats['disk_file_count'] = total_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sample Audio Analysis (Optional - Can Skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SAMPLE AUDIO ANALYSIS (Check a few files)\n",
    "# ============================================================\n",
    "\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAMPLE AUDIO VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Sample 20 random files\n",
    "sample_df = df.sample(n=min(20, len(df)), random_state=42)\n",
    "\n",
    "audio_issues = []\n",
    "sample_results = []\n",
    "\n",
    "for idx, row in tqdm(sample_df.iterrows(), total=len(sample_df), desc=\"Checking audio\"):\n",
    "    audio_path = BASE_DIR / row['audio_path']\n",
    "    \n",
    "    if not audio_path.exists():\n",
    "        audio_issues.append({'utt_id': row['utt_id'], 'issue': 'file_not_found'})\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Load with soundfile (faster)\n",
    "        audio, sr = sf.read(audio_path)\n",
    "        duration = len(audio) / sr\n",
    "        \n",
    "        sample_results.append({\n",
    "            'utt_id': row['utt_id'],\n",
    "            'sr': sr,\n",
    "            'duration_meta': row['duration'],\n",
    "            'duration_actual': round(duration, 3),\n",
    "            'duration_diff': abs(row['duration'] - duration),\n",
    "            'channels': 1 if len(audio.shape) == 1 else audio.shape[1],\n",
    "            'samples': len(audio),\n",
    "            'min_val': audio.min(),\n",
    "            'max_val': audio.max(),\n",
    "        })\n",
    "        \n",
    "        # Check for issues\n",
    "        if sr != 16000:\n",
    "            audio_issues.append({'utt_id': row['utt_id'], 'issue': f'wrong_sr_{sr}'})\n",
    "        if abs(row['duration'] - duration) > 0.1:\n",
    "            audio_issues.append({'utt_id': row['utt_id'], 'issue': f'duration_mismatch_{duration:.2f}_vs_{row[\"duration\"]:.2f}'})\n",
    "            \n",
    "    except Exception as e:\n",
    "        audio_issues.append({'utt_id': row['utt_id'], 'issue': f'load_error_{str(e)[:50]}'})\n",
    "\n",
    "sample_df_results = pd.DataFrame(sample_results)\n",
    "print(f\"\\nSample audio check results:\")\n",
    "print(f\"  Checked:  {len(sample_df)}\")\n",
    "print(f\"  Issues:   {len(audio_issues)}\")\n",
    "\n",
    "if len(sample_results) > 0:\n",
    "    print(f\"\\nSample rate consistency: {sample_df_results['sr'].unique()}\")\n",
    "    print(f\"Duration difference (meta vs actual):\")\n",
    "    print(f\"  Max diff: {sample_df_results['duration_diff'].max():.4f}s\")\n",
    "    print(f\"  Avg diff: {sample_df_results['duration_diff'].mean():.4f}s\")\n",
    "\n",
    "if audio_issues:\n",
    "    print(f\"\\nIssues found:\")\n",
    "    for issue in audio_issues:\n",
    "        print(f\"  {issue['utt_id']}: {issue['issue']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CREATE VISUALIZATIONS\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "fig.suptitle('Dataset Analysis Overview', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Duration distribution\n",
    "ax = axes[0, 0]\n",
    "ax.hist(df['duration'], bins=50, edgecolor='black', alpha=0.7)\n",
    "ax.axvline(df['duration'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"duration\"].mean():.2f}s')\n",
    "ax.axvline(df['duration'].median(), color='green', linestyle='--', label=f'Median: {df[\"duration\"].median():.2f}s')\n",
    "ax.set_xlabel('Duration (seconds)')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Duration Distribution')\n",
    "ax.legend()\n",
    "\n",
    "# 2. Dataset split\n",
    "ax = axes[0, 1]\n",
    "dataset_counts = df['dataset'].value_counts()\n",
    "ax.pie(dataset_counts.values, labels=dataset_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "ax.set_title('By Dataset (VCTK vs ESD)')\n",
    "\n",
    "# 3. Gender split\n",
    "ax = axes[0, 2]\n",
    "gender_counts = df['gender'].value_counts()\n",
    "colors = ['#ff9999', '#66b3ff', '#99ff99']\n",
    "ax.pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%', startangle=90, colors=colors[:len(gender_counts)])\n",
    "ax.set_title('By Gender')\n",
    "\n",
    "# 4. Emotion distribution\n",
    "ax = axes[1, 0]\n",
    "emotion_counts = df['emotion'].value_counts()\n",
    "bars = ax.bar(emotion_counts.index, emotion_counts.values, edgecolor='black')\n",
    "ax.set_xlabel('Emotion')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Emotion Distribution')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "for bar, count in zip(bars, emotion_counts.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 100, f'{count:,}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# 5. Utterances per speaker\n",
    "ax = axes[1, 1]\n",
    "utts_per_speaker = df.groupby('speaker_id').size()\n",
    "ax.hist(utts_per_speaker, bins=30, edgecolor='black', alpha=0.7)\n",
    "ax.axvline(utts_per_speaker.mean(), color='red', linestyle='--', label=f'Mean: {utts_per_speaker.mean():.0f}')\n",
    "ax.set_xlabel('Utterances per Speaker')\n",
    "ax.set_ylabel('Number of Speakers')\n",
    "ax.set_title('Utterances per Speaker Distribution')\n",
    "ax.legend()\n",
    "\n",
    "# 6. Split distribution\n",
    "ax = axes[1, 2]\n",
    "split_counts = df['split'].value_counts()\n",
    "colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
    "bars = ax.bar(split_counts.index, split_counts.values, color=colors, edgecolor='black')\n",
    "ax.set_xlabel('Split')\n",
    "ax.set_ylabel('Utterances')\n",
    "ax.set_title('Train/Val/Test Split')\n",
    "for bar, count in zip(bars, split_counts.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 100, f'{count:,}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(STATS_DIR / 'dataset_overview.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"\\nâœ… Saved: {STATS_DIR / 'dataset_overview.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ACCENT DISTRIBUTION (VCTK)\n",
    "# ============================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "accent_counts = df['accent'].value_counts().head(15)  # Top 15 accents\n",
    "bars = ax.barh(accent_counts.index, accent_counts.values, edgecolor='black')\n",
    "ax.set_xlabel('Number of Utterances')\n",
    "ax.set_ylabel('Accent')\n",
    "ax.set_title('Top 15 Accents by Utterance Count')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "for bar, count in zip(bars, accent_counts.values):\n",
    "    ax.text(bar.get_width() + 100, bar.get_y() + bar.get_height()/2, f'{count:,}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(STATS_DIR / 'accent_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"âœ… Saved: {STATS_DIR / 'accent_distribution.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DURATION BY EMOTION AND DATASET\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Duration by emotion\n",
    "ax = axes[0]\n",
    "df.boxplot(column='duration', by='emotion', ax=ax)\n",
    "ax.set_xlabel('Emotion')\n",
    "ax.set_ylabel('Duration (seconds)')\n",
    "ax.set_title('Duration by Emotion')\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "\n",
    "# Duration by dataset\n",
    "ax = axes[1]\n",
    "df.boxplot(column='duration', by='dataset', ax=ax)\n",
    "ax.set_xlabel('Dataset')\n",
    "ax.set_ylabel('Duration (seconds)')\n",
    "ax.set_title('Duration by Dataset')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(STATS_DIR / 'duration_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"âœ… Saved: {STATS_DIR / 'duration_analysis.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save All Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SAVE COMPREHENSIVE STATISTICS\n",
    "# ============================================================\n",
    "\n",
    "# Add timestamp\n",
    "stats['generated_at'] = datetime.now().isoformat()\n",
    "stats['metadata_path'] = str(METADATA_PATH)\n",
    "\n",
    "# Save as JSON\n",
    "stats_json_path = STATS_DIR / 'dataset_statistics.json'\n",
    "\n",
    "# Convert numpy types to Python types for JSON serialization\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, (np.int64, np.int32)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.float64, np.float32)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(i) for i in obj]\n",
    "    return obj\n",
    "\n",
    "stats_serializable = convert_to_serializable(stats)\n",
    "\n",
    "with open(stats_json_path, 'w') as f:\n",
    "    json.dump(stats_serializable, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Saved: {stats_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SAVE PER-SPEAKER STATISTICS\n",
    "# ============================================================\n",
    "\n",
    "speaker_stats_path = STATS_DIR / 'speaker_statistics.csv'\n",
    "speaker_stats.to_csv(speaker_stats_path)\n",
    "print(f\"âœ… Saved: {speaker_stats_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SAVE SPLIT SPEAKER LISTS\n",
    "# ============================================================\n",
    "\n",
    "# Detailed split info with speaker metadata\n",
    "split_details = []\n",
    "\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    for spk in splits[split_name]['speakers']:\n",
    "        spk_data = speaker_stats.loc[spk] if spk in speaker_stats.index else {}\n",
    "        split_details.append({\n",
    "            'speaker_id': spk,\n",
    "            'split': split_name,\n",
    "            'dataset': spk_data.get('dataset', ''),\n",
    "            'gender': spk_data.get('gender', ''),\n",
    "            'utterances': spk_data.get('utterances', 0),\n",
    "            'minutes': spk_data.get('minutes', 0),\n",
    "        })\n",
    "\n",
    "split_details_df = pd.DataFrame(split_details)\n",
    "split_details_path = STATS_DIR / 'split_details.csv'\n",
    "split_details_df.to_csv(split_details_path, index=False)\n",
    "print(f\"âœ… Saved: {split_details_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GENERATE SUMMARY REPORT\n",
    "# ============================================================\n",
    "\n",
    "report = f\"\"\"\n",
    "================================================================================\n",
    "DATASET ANALYSIS REPORT\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "================================================================================\n",
    "\n",
    "OVERVIEW\n",
    "--------\n",
    "Total utterances:     {stats['total_utterances']:,}\n",
    "Total speakers:       {stats['total_speakers']}\n",
    "Total duration:       {stats['total_duration_hours']:.2f} hours\n",
    "\n",
    "DURATION STATISTICS\n",
    "-------------------\n",
    "Min:    {stats['min_duration']:.2f}s\n",
    "Max:    {stats['max_duration']:.2f}s\n",
    "Mean:   {stats['avg_duration']:.2f}s\n",
    "Median: {stats['median_duration']:.2f}s\n",
    "Std:    {stats['std_duration']:.2f}s\n",
    "\n",
    "BY DATASET\n",
    "----------\n",
    "{dataset_stats.to_string()}\n",
    "\n",
    "BY GENDER\n",
    "---------\n",
    "{gender_stats.to_string()}\n",
    "\n",
    "BY EMOTION\n",
    "----------\n",
    "{emotion_stats.to_string()}\n",
    "\n",
    "TRAIN/VAL/TEST SPLIT\n",
    "--------------------\n",
    "{split_stats.to_string()}\n",
    "\n",
    "FILE VERIFICATION\n",
    "-----------------\n",
    "Files on disk:     {stats.get('disk_file_count', 'N/A'):,}\n",
    "Files in metadata: {stats['total_utterances']:,}\n",
    "Missing files:     {stats['file_verification']['missing']}\n",
    "\n",
    "================================================================================\n",
    "FILES SAVED\n",
    "================================================================================\n",
    "- {STATS_DIR}/dataset_statistics.json\n",
    "- {STATS_DIR}/speaker_statistics.csv\n",
    "- {STATS_DIR}/split_details.csv\n",
    "- {STATS_DIR}/dataset_overview.png\n",
    "- {STATS_DIR}/accent_distribution.png\n",
    "- {STATS_DIR}/duration_analysis.png\n",
    "- {STATS_DIR}/analysis_report.txt\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "report_path = STATS_DIR / 'analysis_report.txt'\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(report)\n",
    "print(f\"\\nâœ… Saved: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Extraction Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ESTIMATE FEATURE EXTRACTION TIME & STORAGE\n",
    "# ============================================================\n",
    "\n",
    "total_hours = stats['total_duration_hours']\n",
    "total_utts = stats['total_utterances']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE EXTRACTION ESTIMATES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBased on {total_utts:,} utterances ({total_hours:.1f} hours of audio)\")\n",
    "\n",
    "estimates = [\n",
    "    {'feature': 'HuBERT continuous', 'gpu': True, 'time_per_utt': 0.1, 'storage_gb': 15},\n",
    "    {'feature': 'K-means training (5 models)', 'gpu': True, 'time_per_utt': 0, 'storage_gb': 0.1, 'fixed_time': 2.5},\n",
    "    {'feature': 'K-means assignment (all K)', 'gpu': False, 'time_per_utt': 0.01, 'storage_gb': 2},\n",
    "    {'feature': 'FACodec (all codes)', 'gpu': True, 'time_per_utt': 0.2, 'storage_gb': 10},\n",
    "    {'feature': 'EnCodec latents', 'gpu': True, 'time_per_utt': 0.1, 'storage_gb': 8},\n",
    "    {'feature': 'F0 (CREPE)', 'gpu': True, 'time_per_utt': 0.3, 'storage_gb': 2},\n",
    "    {'feature': 'Energy', 'gpu': False, 'time_per_utt': 0.01, 'storage_gb': 0.5},\n",
    "    {'feature': 'Speaker embeddings (ECAPA)', 'gpu': True, 'time_per_utt': 0.05, 'storage_gb': 0.5},\n",
    "    {'feature': 'MFA alignment', 'gpu': False, 'time_per_utt': 1.0, 'storage_gb': 1},\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Feature':<30} {'GPU?':<6} {'Est. Time':<15} {'Storage':<10}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "total_gpu_time = 0\n",
    "total_cpu_time = 0\n",
    "total_storage = 0\n",
    "\n",
    "for est in estimates:\n",
    "    if 'fixed_time' in est:\n",
    "        time_hrs = est['fixed_time']\n",
    "    else:\n",
    "        time_hrs = (est['time_per_utt'] * total_utts) / 3600\n",
    "    \n",
    "    if est['gpu']:\n",
    "        total_gpu_time += time_hrs\n",
    "    else:\n",
    "        total_cpu_time += time_hrs\n",
    "    \n",
    "    total_storage += est['storage_gb']\n",
    "    \n",
    "    gpu_str = 'âœ… GPU' if est['gpu'] else 'âŒ CPU'\n",
    "    time_str = f\"{time_hrs:.1f} hours\"\n",
    "    storage_str = f\"{est['storage_gb']:.1f} GB\"\n",
    "    \n",
    "    print(f\"{est['feature']:<30} {gpu_str:<6} {time_str:<15} {storage_str:<10}\")\n",
    "\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'TOTAL GPU TIME':<30} {'':6} {total_gpu_time:.1f} hours\")\n",
    "print(f\"{'TOTAL CPU TIME':<30} {'':6} {total_cpu_time:.1f} hours\")\n",
    "print(f\"{'TOTAL STORAGE':<30} {'':6} {'':<15} {total_storage:.1f} GB\")\n",
    "print(f\"\\nâš¡ With parallelization: ~{max(total_gpu_time, total_cpu_time):.1f} hours wall time\")\n",
    "\n",
    "# Save estimates\n",
    "estimates_path = STATS_DIR / 'extraction_estimates.json'\n",
    "with open(estimates_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'total_utterances': total_utts,\n",
    "        'total_hours_audio': total_hours,\n",
    "        'estimates': estimates,\n",
    "        'total_gpu_time_hours': total_gpu_time,\n",
    "        'total_cpu_time_hours': total_cpu_time,\n",
    "        'total_storage_gb': total_storage,\n",
    "    }, f, indent=2)\n",
    "print(f\"\\nâœ… Saved: {estimates_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… DATASET ANALYSIS COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "ðŸ“Š YOUR DATASET:\n",
    "   â€¢ {stats['total_utterances']:,} utterances\n",
    "   â€¢ {stats['total_speakers']} speakers (109 VCTK + 10 ESD)\n",
    "   â€¢ {stats['total_duration_hours']:.1f} hours of audio\n",
    "   â€¢ Split: 70% train / 15% val / 15% test (by speaker)\n",
    "\n",
    "ðŸ“ FILES CREATED IN {STATS_DIR}:\n",
    "   â€¢ dataset_statistics.json    - All stats in JSON format\n",
    "   â€¢ speaker_statistics.csv     - Per-speaker breakdown\n",
    "   â€¢ split_details.csv          - Speaker assignments to splits\n",
    "   â€¢ analysis_report.txt        - Human-readable report\n",
    "   â€¢ dataset_overview.png       - Overview visualizations\n",
    "   â€¢ accent_distribution.png    - Accent breakdown\n",
    "   â€¢ duration_analysis.png      - Duration distributions\n",
    "   â€¢ extraction_estimates.json  - Time/storage estimates\n",
    "\n",
    "ðŸš€ NEXT STEPS:\n",
    "   1. Run feature extraction (HuBERT, FACodec, F0, etc.)\n",
    "   2. Train probes on extracted features\n",
    "   3. Build leakage matrix\n",
    "\"\"\")\n",
    "\n",
    "# List all files in stats directory\n",
    "print(f\"\\nðŸ“‚ Contents of {STATS_DIR}:\")\n",
    "for f in sorted(STATS_DIR.iterdir()):\n",
    "    size = f.stat().st_size\n",
    "    if size > 1024*1024:\n",
    "        size_str = f\"{size/1024/1024:.1f} MB\"\n",
    "    elif size > 1024:\n",
    "        size_str = f\"{size/1024:.1f} KB\"\n",
    "    else:\n",
    "        size_str = f\"{size} B\"\n",
    "    print(f\"   {f.name:<35} {size_str:>10}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
